from flask import Flask, send_file
from transformers import T5ForConditionalGeneration
import torch
import os

app = Flask(__name__)

# ì„¤ì •ê°’
ORIGINAL_MODEL_DIR = "download_model/client_model_dir"
LITE_MODEL = "client_part.ptl"
SPLIT_LAYER = 4

# í´ë¼ì´ì–¸íŠ¸ ì¸¡ ì¸ì½”ë” ì •ì˜
class ClientEncoder(torch.nn.Module):
    def __init__(self, full_model, split_layer):
        super().__init__()
        self.encoder = full_model.get_encoder()
        self.split_layer = split_layer
        self.partial_layers = torch.nn.ModuleList(self.encoder.block[:split_layer])
        self.encoder_embed = self.encoder.embed_tokens
        self.encoder_norm = self.encoder.final_layer_norm
        self.encoder_dropout = self.encoder.dropout

    def forward(self, input_ids, attention_mask):
        embeddings = self.encoder_embed(input_ids)
        hidden_states = self.encoder_dropout(embeddings)

        for i in range(self.split_layer):
            hidden_states = self.partial_layers[i](hidden_states, attention_mask=attention_mask)[0]

        hidden_states = self.encoder_norm(hidden_states)
        return hidden_states

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸
@app.route("/download_model", methods=["GET"])
def download():
    if not os.path.exists(LITE_MODEL):
        print("âš ï¸ Lite ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ â†’ ìƒˆë¡œ ìƒì„± ì¤‘")

        # ì›ë³¸ T5 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
        model = T5ForConditionalGeneration.from_pretrained(ORIGINAL_MODEL_DIR)
        model.eval()

        # Splitëœ client encoder ìƒì„±
        client_model = ClientEncoder(model, SPLIT_LAYER)
        client_model.eval()

        # dummy ì…ë ¥
        dummy_input_ids = torch.ones(1, 128, dtype=torch.long)
        dummy_attention_mask = torch.ones(1, 128, dtype=torch.long)

        # TorchScript trace ë³€í™˜ í›„ ì €ì¥
        traced_model = torch.jit.trace(client_model, (dummy_input_ids, dummy_attention_mask))
        traced_model._save_for_lite_interpreter(LITE_MODEL)

        print("âœ… ëª¨ë¸ ë³€í™˜ ë° ì €ì¥ ì™„ë£Œ")

    # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ ì‹œ ì‚¬ì´ì¦ˆ ì¶œë ¥
    #file_size = os.path.getsize(LITE_MODEL)
    #print(f"ğŸ“¦ Serving model file: {LITE_MODEL}, size = {file_size} bytes")

    #return send_file(LITE_MODEL, mimetype='application/octet-stream', as_attachment=True)
    print("ğŸ“¤ [SERVER] ëª¨ë¸ ì „ì†¡ ì‹œì‘")
    return send_file(
        LITE_MODEL,
        as_attachment=True,
        conditional=False  # ê°•ì œë¡œ ì „ì²´ íŒŒì¼ ì „ì†¡
    )

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000)
